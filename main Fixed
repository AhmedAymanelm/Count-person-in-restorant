import cv2
import random
import numpy as np
from ultralytics import YOLO
from deep_sort_realtime.deepsort_tracker import DeepSort

# -----------------------------
# Load YOLO
# -----------------------------
print("Loading YOLO model...")
model = YOLO("yolo11x.pt")
print("Model loaded!")

# -----------------------------
# DeepSORT + Re-ID
# -----------------------------
tracker = DeepSort(
    max_age=300,
    n_init=5,                # زيادة لتثبيت track_id
    max_iou_distance=0.6,    # أقل شوية عشان يقلل تغييرات الـ ID
    embedder="torchreid",
    embedder_model_name="osnet_x0_5",
    half=True
)

# -----------------------------
# Lines
# -----------------------------
limitEnter = [700, 300, 900, 700]
limitExit = [600, 300, 700, 600]

ignore_zone = (0, 0, 200, 500)

video_path = "WhatsApp Video 2025-09-01 at 16.56.14.mp4"
cap = cv2.VideoCapture(video_path)

# -----------------------------
# Tracking counters
# -----------------------------
CounttrackEnter = {}
counttrackExit = {}

# -----------------------------
# VideoWriter
# -----------------------------
w, h, fps = (int(cap.get(x)) for x in (
    cv2.CAP_PROP_FRAME_WIDTH,
    cv2.CAP_PROP_FRAME_HEIGHT,
    cv2.CAP_PROP_FPS
))
if fps <= 0:
    fps = 30

video_writer = cv2.VideoWriter("person_output_fixed.mp4",
                               cv2.VideoWriter_fourcc(*"mp4v"),
                               fps, (w, h))
if not video_writer.isOpened():
    print("Error opening video writer")
    exit()

id_colors = {}
frame_count = 0
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

# -----------------------------
# Person features for stable ID
# -----------------------------
person_features = {}  # track_id -> feature vector

# -----------------------------
# Main loop
# -----------------------------
while cap.isOpened():
    success, frame = cap.read()
    if not success:
        break

    frame_count += 1
    if frame_count % 30 == 0:
        progress = (frame_count / total_frames) * 100 if total_frames > 0 else 0
        print(f"Processing frame {frame_count}/{total_frames} ({progress:.1f}%)")

    results = model(frame, classes=[0], verbose=False)
    detections = []

    for result in results:
        for box in result.boxes:
            conf = float(box.conf[0])
            cls = int(box.cls[0])
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            if cls == 0 and conf > 0.4:
                if (ignore_zone[0] <= x1 <= ignore_zone[2] and
                    ignore_zone[1] <= y1 <= ignore_zone[3]):
                    continue
                detections.append([[x1, y1, x2 - x1, y2 - y1], conf, "person"])

    # -----------------------------
    # Update tracks
    # -----------------------------
    tracks = tracker.update_tracks(detections, frame=frame)

    # Draw lines
    cv2.line(frame, (limitEnter[0], limitEnter[1]), (limitEnter[2], limitEnter[3]), (0, 255, 0), 2)
    cv2.line(frame, (limitExit[0], limitExit[1]), (limitExit[2], limitExit[3]), (0, 0, 255), 2)

    for track in tracks:
        if not track.is_confirmed() or track.time_since_update > 0:
            continue

        track_id = track.track_id
        Ltrb = track.to_ltrb()
        x1, y1, x2, y2 = map(int, Ltrb)
        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2

        # -----------------------------
        # Assign color
        if track_id not in id_colors:
            id_colors[track_id] = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))
        color = id_colors[track_id]

        # Draw box
        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 3)
        cv2.putText(frame, f"ID {track_id}", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
        cv2.circle(frame, (cx, cy), 5, color, -1)

        # -----------------------------
        # Feature matching to stabilize ID
        if track_id not in person_features:
            if track.features is not None and len(track.features) > 0:
                person_features[track_id] = track.features[0]
        else:
            # compare with existing features
            feature = track.features[0] if track.features is not None else None
            if feature is not None:
                stored_feature = person_features[track_id]
                similarity = np.dot(stored_feature, feature) / (np.linalg.norm(stored_feature) * np.linalg.norm(feature))
                if similarity < 0.5:  # if very different, assume new person
                    person_features[track_id] = feature

        # -----------------------------
        # Counting
        if limitEnter[0] < cx < limitEnter[2] and limitEnter[1] < cy < limitEnter[3]:
            CounttrackEnter[track_id] = True
        if limitExit[0] < cx < limitExit[2] and limitExit[1] < cy < limitExit[3]:
            counttrackExit[track_id] = True

    # -----------------------------
    # Display counters
    cv2.putText(frame, f"Enter: {len(CounttrackEnter)}", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    cv2.putText(frame, f"Exit: {len(counttrackExit)}", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

    video_writer.write(frame)

cap.release()
video_writer.release()
cv2.destroyAllWindows()

print("Processing Complete!")
print(f" Total unique persons detected: {len(set(list(CounttrackEnter.keys()) + list(counttrackExit.keys())))}")
